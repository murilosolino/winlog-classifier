# Importa√ß√£o de bibliotecas
import pandas as pd  # Manipula√ß√£o de dados tabulares
import re  # Express√µes regulares para processamento de texto
from sklearn.feature_extraction.text import TfidfVectorizer  # Vetoriza√ß√£o de texto
from sklearn.model_selection import train_test_split  # Divis√£o de dados para treino/teste
from sklearn.naive_bayes import MultinomialNB  # Algoritmo de classifica√ß√£o Naive Bayes
from sklearn.metrics import classification_report  # M√©tricas de avalia√ß√£o
import matplotlib.pyplot as plt  # Visualiza√ß√£o gr√°fica
import seaborn as sns  # Visualiza√ß√£o estat√≠stica
from nltk.corpus import stopwords  # Palavras irrelevantes para filtragem
from nltk.stem import PorterStemmer  # Redu√ß√£o de palavras √† sua raiz (stemming)
import nltk  # Natural Language Toolkit

# Download das stopwords em portugu√™s (necess√°rio apenas na primeira execu√ß√£o)
nltk.download('stopwords')

def load_logs(file_path):
    """
    Carrega e estrutura os logs a partir de um arquivo de texto
    Teoria: Transforma√ß√£o de dados n√£o estruturados em estruturados (DataFrame)
    """
    with open(file_path, 'r', encoding='utf-8') as file:
        content = file.read().split('\n\n')  # Divide o arquivo em entradas de log
    
    logs = []
    for entry in content:
        if entry.strip():  # Ignora blocos vazios
            log = {}
            for line in entry.split('\n'):  # Processa cada linha do log
                # Extra√ß√£o estruturada usando padr√µes conhecidos
                if line.startswith('Data:'):
                    log['Data'] = line.split(': ', 1)[1]  # Captura o valor ap√≥s o prefixo
                elif line.startswith('Fonte:'):
                    log['Fonte'] = line.split(': ', 1)[1]
                elif line.startswith('ID do Evento:'):
                    log['ID_Evento'] = int(line.split(': ', 1)[1])
                elif line.startswith('Descri√ß√£o:'):
                    log['Descricao'] = line.split(': ', 1)[1]
            logs.append(log)  # Adiciona o log estruturado √† lista
    return pd.DataFrame(logs)  # Converte para DataFrame pandas

def preprocess_text(text):
    """
    Pr√©-processamento de texto para NLP (Natural Language Processing)
    Teoria: Normaliza√ß√£o de texto para melhorar a qualidade da an√°lise
    """
    text = text.lower()  # Normaliza√ß√£o: tudo para min√∫sculas
    text = re.sub(r'[^\w\s]', '', text)  # Remove pontua√ß√£o usando regex
    tokens = text.split()  # Tokeniza√ß√£o: divide o texto em palavras
    
    # Remo√ß√£o de stopwords (palavras sem valor sem√¢ntico)
    stop_words = set(stopwords.words('portuguese'))
    tokens = [word for word in tokens if word not in stop_words]
    
    # Stemming: redu√ß√£o de palavras √† sua raiz gramatical
    stemmer = PorterStemmer()
    tokens = [stemmer.stem(word) for word in tokens]
    
    return ' '.join(tokens)  # Reconstroi o texto processado

def classify_log(descricao):
    """
    Classifica√ß√£o baseada em regras para criar labels iniciais
    Teoria: Cria√ß√£o de dados rotulados para treinamento supervisionado
    """
    criticas = ['erro', 'falhou', 'insuficiente', 'encerrado']
    suspeitas = ['atualiza√ß√£o', 'reiniciado', 'pausado']
    
    # L√≥gica de classifica√ß√£o hier√°rquica
    if any(word in descricao.lower() for word in criticas):
        return 'Cr√≠tico'
    elif any(word in descricao.lower() for word in suspeitas):
        return 'Suspeito'
    else:
        return 'Normal'

# Carregamento dos dados (ETL - Extract, Transform, Load)
df = load_logs('massive_logs_windows.txt')  # Extra√ß√£o e estrutura√ß√£o

# Pr√©-processamento dos dados
df['Descricao_Processada'] = df['Descricao'].apply(preprocess_text)  # Aplica NLP
df['Classificacao'] = df['Descricao'].apply(classify_log)  # Cria labels iniciais

# Vetoriza√ß√£o usando TF-IDF (Term Frequency-Inverse Document Frequency)
# Teoria: Representa√ß√£o num√©rica do texto ponderando a import√¢ncia das palavras
tfidf = TfidfVectorizer(max_features=1000)  # Limita ao top 1000 termos mais relevantes
X = tfidf.fit_transform(df['Descricao_Processada'])  # Transforma texto em vetores
y = df['Classificacao']  # Vari√°vel target

# Divis√£o dos dados para valida√ß√£o do modelo
# Teoria: Separa√ß√£o para evitar overfitting e testar generaliza√ß√£o
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,  # 20% para teste
    random_state=42  # Semente para reprodutibilidade
)

# Cria√ß√£o e treinamento do modelo Naive Bayes Multinomial
# Teoria: Classificador probabil√≠stico baseado no teorema de Bayes
model = MultinomialNB()  # Adequado para dados discretos (contagens de palavras)
model.fit(X_train, y_train)  # Ajuste do modelo aos dados de treino

# Predi√ß√£o e avalia√ß√£o
predictions = model.predict(X)  # Classifica√ß√£o de todos os dados
df['Predicao_IA'] = predictions  # Adiciona previs√µes ao DataFrame

# Sistema de alertas para eventos cr√≠ticos
alertas = df[df['Predicao_IA'] == 'Cr√≠tico']
if not alertas.empty:
    print("\nüö® ALERTAS CR√çTICOS üö®")
    # Itera√ß√£o sobre as linhas do DataFrame filtrado
    for _, row in alertas.iterrows():
        print(f"[{row['Data']}] {row['Fonte']} - {row['Descricao']}")

# Visualiza√ß√£o dos resultados
plt.figure(figsize=(15, 6))  # Define o tamanho da figura

# Gr√°fico 1: Distribui√ß√£o das classifica√ß√µes
plt.subplot(1, 2, 1)  # Cria subplot 1x2 (posi√ß√£o 1)
sns.countplot(
    x='Predicao_IA', 
    data=df, 
    palette={'Normal':'green', 'Suspeito':'orange', 'Cr√≠tico':'red'}  # Esquema de cores
)
plt.title('Distribui√ß√£o de Classifica√ß√µes')  # T√≠tulo do gr√°fico

# Gr√°fico 2: Linha do tempo de eventos
plt.subplot(1, 2, 2)  # Cria subplot 1x2 (posi√ß√£o 2)
df['Data'] = pd.to_datetime(df['Data'])  # Converte para tipo datetime
df.set_index('Data', inplace=True)  # Define a coluna Data como √≠ndice
# Agrupamento por hora e contagem de eventos
df.resample('H')['Predicao_IA'].count().plot(kind='line', marker='o')
plt.title('Atividade de Eventos por Hora')
plt.ylabel('Quantidade de Eventos')

plt.tight_layout()  # Ajuste autom√°tico do layout
plt.show()  # Exibe os gr√°ficos

# Relat√≥rio de performance do modelo
print("\nRelat√≥rio de Classifica√ß√£o:")
print(classification_report(y, predictions))  # M√©tricas detalhadasm